# 데이터셋 가이드

이 가이드는 AWS 데이터 분석 워크샵에서 사용할 데이터셋을 소개하고, 데이터를 다운로드하여 AWS에 업로드하는 방법을 안내합니다.

## 1. 워크샵용 메인 데이터셋

### 1.1 AI Tool Usage by Students 데이터셋

**📊 데이터셋 개요**
- **주제**: 대학생들의 AI 도구 사용 패턴 및 만족도 조사
- **파일 형식**: CSV
- **크기**: 약 3,000개 레코드
- **업데이트**: 2024년 최신 데이터

**🔍 데이터 구조**
```
주요 컬럼:
- Student_Name: 학생 이름
- College_Name: 대학교 이름  
- Stream: 전공 분야 (Engineering, Commerce, Science, Arts 등)
- Year_of_Study: 학년 (1-4)
- AI_Tools_Used: 사용하는 AI 도구 (ChatGPT, Gemini, Copilot 등)
- Daily_Usage_Hours: 일일 사용 시간
- Use_Cases: 사용 목적 (Assignments, Coding Help, Learning 등)
- Trust_in_AI_Tools: AI 도구에 대한 신뢰도 (1-5 척도)
- Impact_on_Grades: 성적에 미치는 영향 (-3 ~ +3 척도)
- Preferred_AI_Tool: 선호하는 AI 도구
- State: 거주 지역
- Device_Used: 사용 기기 (Mobile, Laptop, Tablet)
```

**💡 분석 가능한 인사이트**
1. 전공별 AI 도구 사용 패턴 차이
2. 학년별 사용 트렌드 분석
3. 지역별 디지털 격차 분석
4. AI 도구 사용이 학업 성취도에 미치는 영향
5. 기기별 사용 선호도 분석

## 2. 데이터 다운로드 방법

### 2.1 Kaggle에서 직접 다운로드

**단계별 다운로드 과정:**

1. **Kaggle 계정 생성**
   - [Kaggle.com](https://www.kaggle.com)에 접속
   - "Register" 클릭하여 계정 생성
   - 이메일 인증 완료

2. **데이터셋 페이지 접속**
   - 검색창에 "AI Tool Usage Students" 검색
   - 또는 직접 링크 접속: [AI Tool Usage Dataset](https://www.kaggle.com/datasets)

3. **데이터 다운로드**
   - 데이터셋 페이지에서 "Download" 버튼 클릭
   - ZIP 파일이 다운로드됨
   - 압축 해제하여 CSV 파일 확인

### 2.2 대체 데이터 소스

Kaggle 접근이 어려운 경우 다음 대체 방법을 사용할 수 있습니다:

**공개 데이터 포털:**
- [공공데이터포털](https://www.data.go.kr) - 한국 정부 공개 데이터
- [서울열린데이터광장](https://data.seoul.go.kr) - 서울시 공공 데이터
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) - 학술용 데이터셋

**샘플 데이터 생성:**
필요시 간단한 샘플 데이터를 직접 생성할 수도 있습니다.

## 3. 데이터 준비 및 검증

### 3.1 다운로드한 데이터 확인

다운로드 완료 후 다음 사항을 확인하세요:

**파일 기본 정보:**
- [ ] 파일 형식이 CSV인지 확인
- [ ] 파일 크기가 적절한지 확인 (1-10MB 범위)
- [ ] 파일이 정상적으로 열리는지 확인

**데이터 품질 확인:**
- [ ] 헤더 행이 있는지 확인
- [ ] 컬럼명이 명확한지 확인
- [ ] 데이터에 특수문자나 깨진 글자가 없는지 확인
- [ ] 빈 행이나 불완전한 데이터가 많지 않은지 확인

### 3.2 Excel에서 데이터 미리보기

CSV 파일을 Excel이나 Google Sheets에서 열어 데이터를 미리 확인할 수 있습니다:

1. **Excel에서 열기**
   - CSV 파일을 Excel로 열기
   - 데이터 형태와 구조 확인
   - 첫 10-20행 정도 살펴보기

2. **Google Sheets 사용**
   - Google Drive에 CSV 파일 업로드
   - Google Sheets로 열어서 확인
   - 온라인에서 쉽게 데이터 미리보기 가능

## 4. AWS S3에 데이터 업로드

### 4.1 S3 버킷 폴더 구조 설계

데이터를 체계적으로 관리하기 위한 폴더 구조를 설계합니다:

```
s3://workshop-data-[고유번호]/
├── raw-data/                    # 원본 데이터
│   ├── ai-tool-usage/
│   │   └── students.csv
│   └── backup/
├── processed-data/              # 처리된 데이터
│   └── ai-tool-usage/
├── scripts/                     # 스크립트 (필요시)
└── results/                     # 분석 결과
```

### 4.2 AWS 콘솔을 통한 업로드

**단계별 업로드 과정:**

1. **S3 콘솔 접속**
   - AWS 콘솔에서 S3 서비스로 이동
   - 이전에 생성한 버킷 선택

2. **폴더 생성**
   - "폴더 만들기" 클릭
   - 폴더명: `raw-data` 입력
   - "폴더 만들기" 클릭
   - `raw-data` 폴더 진입 후 `ai-tool-usage` 폴더 생성

3. **파일 업로드**
   - `ai-tool-usage` 폴더 진입
   - "업로드" 버튼 클릭
   - "파일 추가" 클릭하여 CSV 파일 선택
   - 파일명을 `students.csv`로 변경 (선택사항)
   - "업로드" 클릭

4. **업로드 확인**
   - 업로드 완료 메시지 확인
   - 파일 크기와 업로드 시간 확인
   - 파일 클릭하여 속성 정보 확인

### 4.3 업로드 시 주의사항

**파일 이름 규칙:**
- 공백 대신 하이픈(-) 또는 언더스코어(_) 사용
- 특수문자 사용 금지
- 소문자 사용 권장
- 예: `ai-tool-usage-students.csv`

**권한 설정:**
- 기본 설정 유지 (퍼블릭 액세스 차단)
- 필요시에만 권한 수정

## 5. 데이터 검증

### 5.1 S3에서 데이터 확인

업로드 완료 후 다음 방법으로 데이터를 확인할 수 있습니다:

1. **S3 콘솔에서 확인**
   - 업로드한 파일 클릭
   - "다운로드" 버튼으로 파일 재다운로드하여 확인
   - 파일 크기가 원본과 동일한지 확인

2. **S3 Select 사용 (선택사항)**
   - 파일 선택 후 "작업" → "S3 Select로 쿼리"
   - 간단한 SQL로 데이터 미리보기 가능
   - 예: `SELECT * FROM s3object LIMIT 10`

### 5.2 데이터 무결성 확인

**확인 항목:**
- [ ] 파일 크기가 원본과 동일
- [ ] 업로드 시간이 기록됨
- [ ] 파일이 정상적으로 다운로드됨
- [ ] 데이터 내용이 손상되지 않음

## 6. 추가 데이터셋 (선택사항)

워크샵을 확장하고 싶다면 다음 데이터셋들을 추가로 활용할 수 있습니다:

### 6.1 교육 관련 데이터셋
- **Student Performance Dataset**: 학생 성적 데이터
- **Online Learning Engagement**: 온라인 학습 참여도 데이터
- **University Rankings**: 대학 순위 데이터

### 6.2 기술 관련 데이터셋
- **Job Market Analysis**: 채용 시장 분석 데이터
- **Tech Salary Survey**: IT 업계 연봉 조사 데이터
- **Programming Languages Popularity**: 프로그래밍 언어 인기도 데이터

### 6.3 소셜 미디어 데이터셋
- **Social Media Sentiment**: 소셜 미디어 감정 분석 데이터
- **YouTube Trending**: 유튜브 인기 동영상 데이터
- **Twitter Hashtag Analysis**: 트위터 해시태그 분석 데이터

## 7. 데이터 사용 시 주의사항

### 7.1 개인정보 보호
- 실제 개인정보가 포함된 데이터는 사용 금지
- 익명화된 데이터만 사용
- 민감한 정보는 마스킹 처리

### 7.2 저작권 및 라이선스
- 데이터셋의 라이선스 확인
- 상업적 사용 가능 여부 확인
- 출처 명시 의무 확인

### 7.3 데이터 품질
- 결측값이 많은 데이터는 사전 정제 필요
- 중복 데이터 확인 및 제거
- 이상값(Outlier) 확인

## 8. 다음 단계

데이터 업로드가 완료되면 [기본 워크샵 가이드](04-basic-workshop.md)로 이동하여 실제 데이터 분석 파이프라인을 구축해보세요.

## 문제 해결

### 8.1 일반적인 문제
- **파일 업로드 실패**: 파일 크기나 네트워크 연결 확인
- **권한 오류**: IAM 권한 설정 확인
- **파일 형식 오류**: CSV 형식인지 확인

### 8.2 도움말
더 자세한 문제 해결 방법은 [문제 해결 가이드](06-troubleshooting.md)를 참조하세요.

---

**💡 팁**: 
- 데이터 업로드 전에 반드시 백업 보관
- 여러 버전의 데이터가 있다면 날짜를 포함한 파일명 사용
- 대용량 파일은 압축하여 업로드 후 AWS에서 압축 해제