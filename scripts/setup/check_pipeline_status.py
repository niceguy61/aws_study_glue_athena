#!/usr/bin/env python3
"""
ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
S3, Glue, Athena ë¦¬ì†ŒìŠ¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•©ë‹ˆë‹¤.
"""

import boto3
import json
import sys
from botocore.exceptions import ClientError, NoCredentialsError
from datetime import datetime, timedelta
import argparse
from tabulate import tabulate

class PipelineStatusChecker:
    def __init__(self, profile_name=None, region='us-east-1'):
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ê¸° ì´ˆê¸°í™”"""
        self.profile_name = profile_name
        self.region = region
        self.session = None
        self.status_report = {
            'timestamp': datetime.now().isoformat(),
            's3_status': {},
            'glue_status': {},
            'athena_status': {},
            'pipeline_health': 'UNKNOWN'
        }
        
    def setup_session(self):
        """AWS ì„¸ì…˜ ì„¤ì •"""
        try:
            if self.profile_name:
                self.session = boto3.Session(profile_name=self.profile_name, region_name=self.region)
            else:
                self.session = boto3.Session(region_name=self.region)
            return True
        except Exception as e:
            print(f"âŒ AWS ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return False
    
    def check_s3_resources(self, bucket_name):
        """S3 ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸"""
        s3 = self.session.client('s3')
        s3_status = {
            'bucket_exists': False,
            'raw_data_count': 0,
            'processed_data_count': 0,
            'total_size_mb': 0,
            'folders': []
        }
        
        try:
            # ë²„í‚· ì¡´ì¬ í™•ì¸
            s3.head_bucket(Bucket=bucket_name)
            s3_status['bucket_exists'] = True
            
            # ë²„í‚· ë‚´ ê°ì²´ ëª©ë¡ ì¡°íšŒ
            paginator = s3.get_paginator('list_objects_v2')
            total_size = 0
            folders = set()
            raw_count = 0
            processed_count = 0
            
            for page in paginator.paginate(Bucket=bucket_name):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        key = obj['Key']
                        size = obj['Size']
                        total_size += size
                        
                        # í´ë” êµ¬ì¡° íŒŒì•…
                        if '/' in key:
                            folder = key.split('/')[0]
                            folders.add(folder)
                        
                        # ì›ë³¸/ì²˜ë¦¬ëœ ë°ì´í„° êµ¬ë¶„
                        if 'raw' in key.lower() or 'source' in key.lower():
                            raw_count += 1
                        elif 'processed' in key.lower() or 'output' in key.lower():
                            processed_count += 1
            
            s3_status.update({
                'raw_data_count': raw_count,
                'processed_data_count': processed_count,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'folders': list(folders)
            })
            
        except ClientError as e:
            if e.response['Error']['Code'] == 'NoSuchBucket':
                s3_status['error'] = f'ë²„í‚· {bucket_name}ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'
            else:
                s3_status['error'] = f'S3 ì ‘ê·¼ ì˜¤ë¥˜: {e.response["Error"]["Message"]}'
        
        self.status_report['s3_status'] = s3_status
        return s3_status
    
    def check_glue_resources(self, database_name=None):
        """Glue ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸"""
        glue = self.session.client('glue')
        glue_status = {
            'databases': [],
            'tables': [],
            'crawlers': [],
            'jobs': [],
            'recent_runs': []
        }
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ
            databases = glue.get_databases()
            for db in databases['DatabaseList']:
                db_info = {
                    'name': db['Name'],
                    'description': db.get('Description', ''),
                    'created': db.get('CreateTime', '').isoformat() if db.get('CreateTime') else ''
                }
                glue_status['databases'].append(db_info)
            
            # íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ì¡°íšŒ
            if database_name:
                try:
                    tables = glue.get_tables(DatabaseName=database_name)
                    for table in tables['TableList']:
                        table_info = {
                            'name': table['Name'],
                            'database': table['DatabaseName'],
                            'location': table.get('StorageDescriptor', {}).get('Location', ''),
                            'input_format': table.get('StorageDescriptor', {}).get('InputFormat', ''),
                            'columns': len(table.get('StorageDescriptor', {}).get('Columns', [])),
                            'created': table.get('CreateTime', '').isoformat() if table.get('CreateTime') else ''
                        }
                        glue_status['tables'].append(table_info)
                except ClientError:
                    pass  # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ê±°ë‚˜ ê¶Œí•œ ì—†ìŒ
            
            # í¬ë¡¤ëŸ¬ ëª©ë¡ ì¡°íšŒ
            crawlers = glue.get_crawlers()
            for crawler in crawlers['Crawlers']:
                crawler_info = {
                    'name': crawler['Name'],
                    'state': crawler['State'],
                    'database': crawler.get('DatabaseName', ''),
                    'last_crawl': crawler.get('LastCrawl', {}).get('StartTime', '').isoformat() if crawler.get('LastCrawl', {}).get('StartTime') else '',
                    'status': crawler.get('LastCrawl', {}).get('Status', 'NEVER_RUN')
                }
                glue_status['crawlers'].append(crawler_info)
            
            # ETL ì‘ì—… ëª©ë¡ ì¡°íšŒ
            jobs = glue.get_jobs()
            for job in jobs['Jobs']:
                job_info = {
                    'name': job['Name'],
                    'role': job['Role'],
                    'created': job.get('CreatedOn', '').isoformat() if job.get('CreatedOn') else '',
                    'last_modified': job.get('LastModifiedOn', '').isoformat() if job.get('LastModifiedOn') else ''
                }
                glue_status['jobs'].append(job_info)
                
                # ìµœê·¼ ì‘ì—… ì‹¤í–‰ ê¸°ë¡ ì¡°íšŒ
                try:
                    runs = glue.get_job_runs(JobName=job['Name'], MaxResults=5)
                    for run in runs['JobRuns']:
                        run_info = {
                            'job_name': job['Name'],
                            'run_id': run['Id'],
                            'state': run['JobRunState'],
                            'started': run.get('StartedOn', '').isoformat() if run.get('StartedOn') else '',
                            'completed': run.get('CompletedOn', '').isoformat() if run.get('CompletedOn') else '',
                            'execution_time': run.get('ExecutionTime', 0)
                        }
                        glue_status['recent_runs'].append(run_info)
                except ClientError:
                    pass
            
        except ClientError as e:
            glue_status['error'] = f'Glue ì ‘ê·¼ ì˜¤ë¥˜: {e.response["Error"]["Message"]}'
        
        self.status_report['glue_status'] = glue_status
        return glue_status
    
    def check_athena_resources(self, database_name=None):
        """Athena ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸"""
        athena = self.session.client('athena')
        athena_status = {
            'workgroups': [],
            'recent_queries': [],
            'query_stats': {
                'total_queries': 0,
                'successful_queries': 0,
                'failed_queries': 0,
                'data_scanned_mb': 0
            }
        }
        
        try:
            # ì›Œí¬ê·¸ë£¹ ëª©ë¡ ì¡°íšŒ
            workgroups = athena.list_work_groups()
            for wg in workgroups['WorkGroups']:
                wg_info = {
                    'name': wg['Name'],
                    'state': wg['State'],
                    'description': wg.get('Description', '')
                }
                athena_status['workgroups'].append(wg_info)
            
            # ìµœê·¼ ì¿¼ë¦¬ ì‹¤í–‰ ê¸°ë¡ ì¡°íšŒ
            queries = athena.list_query_executions(MaxResults=20)
            
            total_queries = 0
            successful_queries = 0
            failed_queries = 0
            total_data_scanned = 0
            
            for query_id in queries['QueryExecutionIds']:
                try:
                    query_detail = athena.get_query_execution(QueryExecutionId=query_id)
                    execution = query_detail['QueryExecution']
                    
                    query_info = {
                        'query_id': query_id,
                        'query': execution['Query'][:100] + '...' if len(execution['Query']) > 100 else execution['Query'],
                        'state': execution['Status']['State'],
                        'database': execution.get('QueryExecutionContext', {}).get('Database', ''),
                        'submission_time': execution['Status'].get('SubmissionDateTime', '').isoformat() if execution['Status'].get('SubmissionDateTime') else '',
                        'completion_time': execution['Status'].get('CompletionDateTime', '').isoformat() if execution['Status'].get('CompletionDateTime') else '',
                        'data_scanned_mb': round(execution.get('Statistics', {}).get('DataScannedInBytes', 0) / (1024 * 1024), 2),
                        'execution_time_ms': execution.get('Statistics', {}).get('EngineExecutionTimeInMillis', 0)
                    }
                    
                    athena_status['recent_queries'].append(query_info)
                    
                    # í†µê³„ ì§‘ê³„
                    total_queries += 1
                    if execution['Status']['State'] == 'SUCCEEDED':
                        successful_queries += 1
                    elif execution['Status']['State'] == 'FAILED':
                        failed_queries += 1
                    
                    total_data_scanned += execution.get('Statistics', {}).get('DataScannedInBytes', 0)
                    
                except ClientError:
                    continue
            
            athena_status['query_stats'] = {
                'total_queries': total_queries,
                'successful_queries': successful_queries,
                'failed_queries': failed_queries,
                'data_scanned_mb': round(total_data_scanned / (1024 * 1024), 2)
            }
            
        except ClientError as e:
            athena_status['error'] = f'Athena ì ‘ê·¼ ì˜¤ë¥˜: {e.response["Error"]["Message"]}'
        
        self.status_report['athena_status'] = athena_status
        return athena_status
    
    def assess_pipeline_health(self):
        """íŒŒì´í”„ë¼ì¸ ì „ì²´ ìƒíƒœ í‰ê°€"""
        health_score = 0
        max_score = 0
        issues = []
        
        # S3 ìƒíƒœ í‰ê°€
        s3_status = self.status_report['s3_status']
        if s3_status.get('bucket_exists'):
            health_score += 2
            if s3_status.get('raw_data_count', 0) > 0:
                health_score += 2
            if s3_status.get('processed_data_count', 0) > 0:
                health_score += 2
        else:
            issues.append("S3 ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        max_score += 6
        
        # Glue ìƒíƒœ í‰ê°€
        glue_status = self.status_report['glue_status']
        if len(glue_status.get('databases', [])) > 0:
            health_score += 1
        if len(glue_status.get('tables', [])) > 0:
            health_score += 2
        if len(glue_status.get('crawlers', [])) > 0:
            health_score += 1
            # í¬ë¡¤ëŸ¬ ì„±ê³µ ì‹¤í–‰ í™•ì¸
            successful_crawlers = [c for c in glue_status.get('crawlers', []) if c.get('status') == 'SUCCEEDED']
            if successful_crawlers:
                health_score += 1
        if len(glue_status.get('jobs', [])) > 0:
            health_score += 1
            # ETL ì‘ì—… ì„±ê³µ ì‹¤í–‰ í™•ì¸
            successful_runs = [r for r in glue_status.get('recent_runs', []) if r.get('state') == 'SUCCEEDED']
            if successful_runs:
                health_score += 1
        max_score += 7
        
        # Athena ìƒíƒœ í‰ê°€
        athena_status = self.status_report['athena_status']
        query_stats = athena_status.get('query_stats', {})
        if query_stats.get('total_queries', 0) > 0:
            health_score += 1
            success_rate = query_stats.get('successful_queries', 0) / query_stats.get('total_queries', 1)
            if success_rate > 0.8:
                health_score += 2
            elif success_rate > 0.5:
                health_score += 1
        max_score += 3
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if max_score == 0:
            health_percentage = 0
        else:
            health_percentage = (health_score / max_score) * 100
        
        if health_percentage >= 80:
            pipeline_health = 'HEALTHY'
        elif health_percentage >= 60:
            pipeline_health = 'WARNING'
        elif health_percentage >= 40:
            pipeline_health = 'DEGRADED'
        else:
            pipeline_health = 'CRITICAL'
        
        self.status_report['pipeline_health'] = pipeline_health
        self.status_report['health_score'] = f"{health_score}/{max_score} ({health_percentage:.1f}%)"
        self.status_report['issues'] = issues
        
        return pipeline_health, health_percentage, issues
    
    def print_status_report(self):
        """ìƒíƒœ ë³´ê³ ì„œ ì¶œë ¥"""
        print("ğŸ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë³´ê³ ì„œ")
        print("=" * 60)
        print(f"ğŸ“… ê²€ì‚¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì „ì²´ ìƒíƒœ
        health, percentage, issues = self.assess_pipeline_health()
        health_icon = {
            'HEALTHY': 'ğŸŸ¢',
            'WARNING': 'ğŸŸ¡',
            'DEGRADED': 'ğŸŸ ',
            'CRITICAL': 'ğŸ”´'
        }.get(health, 'âšª')
        
        print(f"\nğŸ¯ ì „ì²´ ìƒíƒœ: {health_icon} {health} ({self.status_report['health_score']})")
        
        if issues:
            print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                print(f"   â€¢ {issue}")
        
        # S3 ìƒíƒœ
        print(f"\nğŸ“¦ S3 ìŠ¤í† ë¦¬ì§€ ìƒíƒœ:")
        s3_status = self.status_report['s3_status']
        if s3_status.get('bucket_exists'):
            print(f"   âœ… ë²„í‚· ì¡´ì¬: ì˜ˆ")
            print(f"   ğŸ“ í´ë” ìˆ˜: {len(s3_status.get('folders', []))}")
            print(f"   ğŸ“„ ì›ë³¸ íŒŒì¼: {s3_status.get('raw_data_count', 0)}ê°œ")
            print(f"   ğŸ”„ ì²˜ë¦¬ëœ íŒŒì¼: {s3_status.get('processed_data_count', 0)}ê°œ")
            print(f"   ğŸ’¾ ì´ í¬ê¸°: {s3_status.get('total_size_mb', 0)} MB")
            if s3_status.get('folders'):
                print(f"   ğŸ“‚ í´ë” ëª©ë¡: {', '.join(s3_status['folders'])}")
        else:
            print(f"   âŒ ë²„í‚· ìƒíƒœ: {s3_status.get('error', 'ì ‘ê·¼ ë¶ˆê°€')}")
        
        # Glue ìƒíƒœ
        print(f"\nğŸ”§ Glue ETL ìƒíƒœ:")
        glue_status = self.status_report['glue_status']
        if not glue_status.get('error'):
            print(f"   ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤: {len(glue_status.get('databases', []))}ê°œ")
            print(f"   ğŸ“‹ í…Œì´ë¸”: {len(glue_status.get('tables', []))}ê°œ")
            print(f"   ğŸ•·ï¸ í¬ë¡¤ëŸ¬: {len(glue_status.get('crawlers', []))}ê°œ")
            print(f"   âš™ï¸ ETL ì‘ì—…: {len(glue_status.get('jobs', []))}ê°œ")
            
            # í¬ë¡¤ëŸ¬ ìƒíƒœ ìƒì„¸
            if glue_status.get('crawlers'):
                print(f"\n   í¬ë¡¤ëŸ¬ ìƒì„¸:")
                crawler_data = []
                for crawler in glue_status['crawlers']:
                    crawler_data.append([
                        crawler['name'],
                        crawler['state'],
                        crawler.get('status', 'N/A'),
                        crawler.get('last_crawl', 'Never')[:19] if crawler.get('last_crawl') else 'Never'
                    ])
                print("   " + tabulate(crawler_data, headers=['ì´ë¦„', 'ìƒíƒœ', 'ë§ˆì§€ë§‰ ì‹¤í–‰', 'ì‹¤í–‰ ì‹œê°„'], tablefmt='simple'))
            
            # ìµœê·¼ ETL ì‹¤í–‰ ê¸°ë¡
            if glue_status.get('recent_runs'):
                print(f"\n   ìµœê·¼ ETL ì‹¤í–‰ ê¸°ë¡:")
                run_data = []
                for run in glue_status['recent_runs'][:5]:  # ìµœê·¼ 5ê°œë§Œ
                    run_data.append([
                        run['job_name'],
                        run['state'],
                        run.get('started', 'N/A')[:19] if run.get('started') else 'N/A',
                        f"{run.get('execution_time', 0)}ì´ˆ"
                    ])
                print("   " + tabulate(run_data, headers=['ì‘ì—…ëª…', 'ìƒíƒœ', 'ì‹œì‘ ì‹œê°„', 'ì‹¤í–‰ ì‹œê°„'], tablefmt='simple'))
        else:
            print(f"   âŒ Glue ìƒíƒœ: {glue_status['error']}")
        
        # Athena ìƒíƒœ
        print(f"\nğŸ” Athena ì¿¼ë¦¬ ìƒíƒœ:")
        athena_status = self.status_report['athena_status']
        if not athena_status.get('error'):
            stats = athena_status.get('query_stats', {})
            print(f"   ğŸ“Š ì´ ì¿¼ë¦¬ ìˆ˜: {stats.get('total_queries', 0)}ê°œ")
            print(f"   âœ… ì„±ê³µí•œ ì¿¼ë¦¬: {stats.get('successful_queries', 0)}ê°œ")
            print(f"   âŒ ì‹¤íŒ¨í•œ ì¿¼ë¦¬: {stats.get('failed_queries', 0)}ê°œ")
            print(f"   ğŸ“ˆ ìŠ¤ìº”í•œ ë°ì´í„°: {stats.get('data_scanned_mb', 0)} MB")
            
            # ìµœê·¼ ì¿¼ë¦¬ ê¸°ë¡
            if athena_status.get('recent_queries'):
                print(f"\n   ìµœê·¼ ì¿¼ë¦¬ ê¸°ë¡:")
                query_data = []
                for query in athena_status['recent_queries'][:5]:  # ìµœê·¼ 5ê°œë§Œ
                    query_data.append([
                        query['query'][:50] + '...' if len(query['query']) > 50 else query['query'],
                        query['state'],
                        query.get('database', 'N/A'),
                        f"{query.get('data_scanned_mb', 0)} MB"
                    ])
                print("   " + tabulate(query_data, headers=['ì¿¼ë¦¬', 'ìƒíƒœ', 'ë°ì´í„°ë² ì´ìŠ¤', 'ìŠ¤ìº” ë°ì´í„°'], tablefmt='simple'))
        else:
            print(f"   âŒ Athena ìƒíƒœ: {athena_status['error']}")
        
        print("\n" + "=" * 60)
        
        return health == 'HEALTHY'

def main():
    parser = argparse.ArgumentParser(description='ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ ë„êµ¬')
    parser.add_argument('--profile', help='AWS í”„ë¡œí•„ ì´ë¦„')
    parser.add_argument('--region', default='us-east-1', help='AWS ë¦¬ì „ (ê¸°ë³¸ê°’: us-east-1)')
    parser.add_argument('--bucket', required=True, help='í™•ì¸í•  S3 ë²„í‚· ì´ë¦„')
    parser.add_argument('--database', help='í™•ì¸í•  Glue ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„')
    parser.add_argument('--output', help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥')
    parser.add_argument('--quiet', action='store_true', help='ìš”ì•½ ê²°ê³¼ë§Œ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # ìƒíƒœ í™•ì¸ê¸° ìƒì„± ë° ì‹¤í–‰
    checker = PipelineStatusChecker(profile_name=args.profile, region=args.region)
    
    if not checker.setup_session():
        sys.exit(1)
    
    print("ğŸ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ì¤‘...\n")
    
    # ê° ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    checker.check_s3_resources(args.bucket)
    checker.check_glue_resources(args.database)
    checker.check_athena_resources(args.database)
    
    # ê²°ê³¼ ì¶œë ¥
    if not args.quiet:
        is_healthy = checker.print_status_report()
    else:
        health, percentage, issues = checker.assess_pipeline_health()
        print(f"íŒŒì´í”„ë¼ì¸ ìƒíƒœ: {health} ({percentage:.1f}%)")
        if issues:
            print(f"ë¬¸ì œ: {len(issues)}ê°œ ë°œê²¬")
        is_healthy = health == 'HEALTHY'
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(checker.status_report, f, indent=2, ensure_ascii=False)
        print(f"\nê²°ê³¼ê°€ {args.output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
    sys.exit(0 if is_healthy else 1)

if __name__ == '__main__':
    main()